{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL Quiz\n",
    "\n",
    "This quiz uses the same dataset and questions from the Spark Data Frames Programming Quiz. For this quiz, however, use Spark SQL instead of Spark Data Frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark SQL Quiz\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log.createOrReplaceTempView(\"user_log_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\"(empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = spark.sql('''\n",
    "    SELECT DISTINCT page\n",
    "    FROM user_log_table\n",
    "    WHERE userId=\"\"\n",
    "    '''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = spark.sql('''\n",
    "    SELECT DISTINCT page\n",
    "    FROM user_log_table\n",
    "    '''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(page='Submit Downgrade'),\n",
       " Row(page='Downgrade'),\n",
       " Row(page='Logout'),\n",
       " Row(page='Save Settings'),\n",
       " Row(page='Settings'),\n",
       " Row(page='NextSong'),\n",
       " Row(page='Upgrade'),\n",
       " Row(page='Error'),\n",
       " Row(page='Submit Upgrade')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y.subtract(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "|page|            page|\n",
      "+----+----------------+\n",
      "|null|Submit Downgrade|\n",
      "|null|       Downgrade|\n",
      "|null|          Logout|\n",
      "|null|   Save Settings|\n",
      "|null|        Settings|\n",
      "|null|        NextSong|\n",
      "|null|         Upgrade|\n",
      "|null|           Error|\n",
      "|null|  Submit Upgrade|\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SELECT distinct pages for the blank user and distinc pages for all users\n",
    "# Right join the results to find pages that blank visitor did not visit\n",
    "spark.sql(\"SELECT * \\\n",
    "            FROM ( \\\n",
    "                SELECT DISTINCT page \\\n",
    "                FROM user_log_table \\\n",
    "                WHERE userId='') AS user_pages \\\n",
    "            RIGHT JOIN ( \\\n",
    "                SELECT DISTINCT page \\\n",
    "                FROM user_log_table) AS all_pages \\\n",
    "            ON user_pages.page = all_pages.page \\\n",
    "            WHERE user_pages.page IS NULL\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "Why might you prefer to use SQL over data frames? Why might you prefer data frames over SQL?\n",
    "no need to load whole data in SQL, calculation done in background if we want, more abstract, pandas more descriptive with more step by step process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(DISTINCT userID)|\n",
      "+----------------------+\n",
      "|                   462|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT COUNT(DISTINCT userID)\n",
    "    FROM user_log_table\n",
    "    WHERE gender=\"F\" AND userId!=\"\"\n",
    "    GROUP BY gender\n",
    "    '''\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|  artist|count(song)|\n",
      "+--------+-----------+\n",
      "|Coldplay|         83|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql('''\n",
    "    SELECT artist, COUNT(song)\n",
    "    FROM user_log_table\n",
    "    WHERE user_log_table.page=\"NextSong\"\n",
    "    GROUP BY artist\n",
    "    ORDER BY COUNT(song) DESC\n",
    "    LIMIT 1\n",
    "    '''\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"Home_visit\", lambda x: 1 if x == \"Home\" else 0)\n",
    "#user_log_valid = user_log_valid.withColumn(\"Home_visit\", Home_visit(\"page\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+--------------------+--------+----------+\n",
      "|userId|           ts|                song|    page|Home_visit|\n",
      "+------+-------------+--------------------+--------+----------+\n",
      "|    10|1513790894284|             Secrets|NextSong|         0|\n",
      "|    10|1513828388284|             Overdue|NextSong|         0|\n",
      "|   100|1513750214284|                1972|NextSong|         0|\n",
      "|   100|1513750442284|             Secrets|NextSong|         0|\n",
      "|   100|1513775431284|                null|    Home|         1|\n",
      "|   100|1513775556284|Don't It Make My ...|NextSong|         0|\n",
      "|   100|1513775710284|Clouds (Of Color ...|NextSong|         0|\n",
      "|   100|1513776194284|                null|    Home|         1|\n",
      "|   100|1513776308284|                0010|NextSong|         0|\n",
      "|   100|1513839673284|                null|    Home|         1|\n",
      "|  1000|1513720878284|       Cheryl Tweedy|NextSong|         0|\n",
      "|  1003|1513749501284|                null|    Home|         1|\n",
      "|  1003|1513749516284|         The Hipster|NextSong|         0|\n",
      "|  1003|1513749525284|                null|    Home|         1|\n",
      "|  1005|1513782278284|      Nuits Blanches|NextSong|         0|\n",
      "|  1006|1513773548284|A Comet Appears (...|NextSong|         0|\n",
      "|  1006|1513773777284|Well Thought Out ...|NextSong|         0|\n",
      "|  1006|1513774019284| Where Is Everybody?|NextSong|         0|\n",
      "|  1017|1513817806284|           Savin' Me|NextSong|         0|\n",
      "|  1017|1513818023284|               Thump|NextSong|         0|\n",
      "|  1017|1513818488284|         Tenuousness|NextSong|         0|\n",
      "|  1017|1513818718284|        Skeleton Boy|NextSong|         0|\n",
      "|  1017|1513818931284|           Old Flame|NextSong|         0|\n",
      "|  1017|1513819172284|            Tive Sim|NextSong|         0|\n",
      "|  1017|1513820906284|                null|    Home|         1|\n",
      "|  1017|1513821152284| Ridiculous Thoughts|NextSong|         0|\n",
      "|  1017|1513821424284|When A Man Is Wro...|NextSong|         0|\n",
      "|  1017|1513821682284|           Blue Fire|NextSong|         0|\n",
      "|  1017|1513822400284|                null|    Home|         1|\n",
      "|  1017|1513822643284|    Ain't Misbehavin|NextSong|         0|\n",
      "+------+-------------+--------------------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT userId, ts, song, page, Home_visit(page) AS Home_visit\n",
    "    FROM user_log_table\n",
    "    WHERE  userId!=\"\" AND (page=\"NextSong\" OR page=\"Home\")\n",
    "    ORDER BY userId, ts\n",
    "    LIMIT 30\n",
    "    '''\n",
    "    ).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_home_table = spark.sql('''\n",
    "    SELECT userId, ts, song, page, Home_visit(page) AS Home_visit\n",
    "    FROM user_log_table\n",
    "    WHERE  userId!=\"\" AND (page=\"NextSong\" OR page=\"Home\")\n",
    "    ORDER BY userId, ts\n",
    "    '''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_home_table.createOrReplaceTempView(\"is_home_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_sum = spark.sql(\"SELECT *, SUM(Home_visit) OVER \\\n",
    "    (PARTITION BY userID ORDER BY ts DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS period \\\n",
    "    FROM is_home_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_sum.createOrReplaceTempView(\"period_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+--------------------+--------+----------+------+\n",
      "|userId|           ts|                song|    page|Home_visit|period|\n",
      "+------+-------------+--------------------+--------+----------+------+\n",
      "|  1436|1513783259284| Throw It In The Bag|NextSong|         0|   0.0|\n",
      "|  1436|1513782858284|Atom Bomb (Atomix 2)|NextSong|         0|   0.0|\n",
      "|  2088|1513805972284|                null|    Home|         1|   1.0|\n",
      "|  2088|1513805859284|          Back To Me|NextSong|         0|   1.0|\n",
      "|  2088|1513805494284|Keep On Hoping [F...|NextSong|         0|   1.0|\n",
      "|  2088|1513805065284|              Shanti|NextSong|         0|   1.0|\n",
      "|  2088|1513804786284|   Rest Of Your Life|NextSong|         0|   1.0|\n",
      "|  2088|1513804555284|Inside The Fire (...|NextSong|         0|   1.0|\n",
      "|  2088|1513804196284|             Siechen|NextSong|         0|   1.0|\n",
      "|  2088|1513803967284|            Spectrum|NextSong|         0|   1.0|\n",
      "|  2088|1513803820284|Wait And Bleed (A...|NextSong|         0|   1.0|\n",
      "|  2088|1513803651284|Wake Up Little Susie|NextSong|         0|   1.0|\n",
      "|  2088|1513803413284|         Skinny Love|NextSong|         0|   1.0|\n",
      "|  2088|1513803254284|  From Blue To Green|NextSong|         0|   1.0|\n",
      "|  2088|1513803057284|         Zon zon zon|NextSong|         0|   1.0|\n",
      "|  2088|1513802824284|          Two Wrongs|NextSong|         0|   1.0|\n",
      "|  2162|1513781246284|   People Gotta Move|NextSong|         0|   0.0|\n",
      "|  2162|1513781065284|Catch You Baby (S...|NextSong|         0|   0.0|\n",
      "|  2162|1513780860284|        Golden Touch|NextSong|         0|   0.0|\n",
      "|  2162|1513780569284|A Time To Be So S...|NextSong|         0|   0.0|\n",
      "+------+-------------+--------------------+--------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT *\n",
    "    FROM period_table\n",
    "    '''\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count_results|\n",
      "+-------------+\n",
      "|            2|\n",
      "|           13|\n",
      "|           19|\n",
      "|           15|\n",
      "|            4|\n",
      "|           17|\n",
      "|            1|\n",
      "|            3|\n",
      "|            3|\n",
      "|           16|\n",
      "|            4|\n",
      "|           11|\n",
      "|            9|\n",
      "|           17|\n",
      "|            3|\n",
      "|            4|\n",
      "|            1|\n",
      "|            1|\n",
      "|            1|\n",
      "|            2|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cusum.filter((cusum.page == 'NextSong')) \\\n",
    "#     .groupBy('userID', 'period') \\\n",
    "#     .agg({'period':'count'}) \\\n",
    "#     .agg({'count(period)':'avg'}).show()\n",
    "\n",
    "spark.sql('''\n",
    "    SELECT COUNT(*) AS count_results\n",
    "    FROM period_table\n",
    "    WHERE page=\"NextSong\"\n",
    "    GROUP BY userId, period\n",
    "    '''\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(count_results)|\n",
      "+------------------+\n",
      "| 6.898347107438017|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT AVG(count_results) FROM\n",
    "    (SELECT COUNT(*) AS count_results\n",
    "    FROM period_table\n",
    "    GROUP BY userId, period, page HAVING page = 'NextSong') AS counts\n",
    "    '''\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
